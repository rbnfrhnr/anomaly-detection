{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bbf903a-9162-425b-ab1e-8740e221ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import SubsequenceRNN\n",
    "from datautils import get_data\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b085324e-f5c9-45b3-9848-f36a50ceb21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda_is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dba26f6-48fb-4b4b-afb2-444e4316829a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    1    2 ...  397  398  399]\n",
      " [   1    2    3 ...  398  399  400]\n",
      " [   2    3    4 ...  399  400  401]\n",
      " ...\n",
      " [7596 7597 7598 ... 7993 7994 7995]\n",
      " [7597 7598 7599 ... 7994 7995 7996]\n",
      " [7598 7599 7600 ... 7995 7996 7997]]\n",
      "torch.Size([7599, 400]) torch.Size([55, 400]) torch.Size([55])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train, test, y = get_data('126', 400)\n",
    "train = torch.Tensor(train)\n",
    "test = torch.Tensor(test)\n",
    "y = torch.Tensor(y)\n",
    "print(train.shape, test.shape, y.shape)\n",
    "# Generators\n",
    "train_dataloader = DataLoader(train, batch_size=10000, shuffle=True)\n",
    "test_dataloader = DataLoader((test, y), batch_size=10000, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de8c3db5-4d58-4425-8c78-19b39f8afce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 250)\n",
      "[173 249  59 218  64 168  71 236  50 228]\n",
      "400\n",
      "[(2, 173), (1, 249), (6, 59), (1, 218), (6, 64), (2, 168), (5, 71), (1, 236), (8, 50), (1, 228)]\n",
      "[GRU(173, 10, num_layers=2, batch_first=True), GRU(249, 10, num_layers=2, batch_first=True), GRU(59, 10, num_layers=2, batch_first=True), GRU(218, 10, num_layers=2, batch_first=True), GRU(64, 10, num_layers=2, batch_first=True), GRU(168, 10, num_layers=2, batch_first=True), GRU(71, 10, num_layers=2, batch_first=True), GRU(236, 10, num_layers=2, batch_first=True), GRU(50, 10, num_layers=2, batch_first=True), GRU(228, 10, num_layers=2, batch_first=True)]\n",
      "Linear(in_features=330, out_features=5, bias=True)\n"
     ]
    }
   ],
   "source": [
    "model = SubsequenceRNN((400), 5, n_subsequences=10, ranges=(50,250))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11faf680-a552-4dcd-9f6d-ec3e180719b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c433f88-fc61-49c5-b161-b871e8b22907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0 loss 505158.3125\n",
      "batch 1 loss 486936.40625\n",
      "batch 2 loss 473580.25\n",
      "batch 3 loss 464449.125\n",
      "batch 4 loss 459342.5625\n",
      "batch 5 loss 457183.90625\n",
      "batch 6 loss 456483.0\n",
      "batch 7 loss 456145.53125\n",
      "batch 8 loss 455450.3125\n",
      "batch 9 loss 453975.46875\n",
      "batch 10 loss 451665.40625\n",
      "batch 11 loss 448770.09375\n",
      "batch 12 loss 445622.8125\n",
      "batch 13 loss 442477.4375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for t in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    model.train()\n",
    "    \n",
    "    batch_loss_hist = []\n",
    "    for batch, X in enumerate(train_dataloader):\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        batch_loss = criterion(pred, X)\n",
    "        \n",
    "        optimizer.zero_grad() \n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss_hist.append(batch_loss.item())\n",
    "    print('batch', t,'loss', np.mean(np.array(batch_loss_hist)))\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "\n",
    "\n",
    "# print(model.rnns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed1bfb-5401-4490-9b8c-f1f50139ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.to(device)\n",
    "y_pred = model(test)\n",
    "recon_loss = torch.mean((test - y_pred)**2, axis=1)\n",
    "print(recon_loss.shape, recon_loss.max(), recon_loss.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7131d1c4-8558-4c49-9a1d-d70b7c5e434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_anomaly_idx = torch.argmax(recon_loss)\n",
    "\n",
    "print(torch.argmax(recon_loss).detach().numpy(), torch.argwhere(y == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09af5bf2-99fa-477b-83a8-2fc62a5d381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(2,1,figsize=(20,10))\n",
    "ax[0].step(np.arange(55), recon_loss.detach().numpy())\n",
    "ax[1].step(np.arange(55), y.detach().numpy())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
