# used as an identifier to group runs and for wandbb logging group
experiment-name: augmentation-reverse

# yes / no
use-gpu: yes

model:
  type: autoencoder
  sub-type: RNN

  # specific to model-type and sub-type
  config:
    encoding-layers:
      - class-name: GRU
        arguments:
          units: 10
      - class-name: LeakyReLU
        arguments:
          alpha: 0.1
    decoding-layers:
      - class-name: GRU
        arguments:
          units: 10
          return_sequences: True
    optimizer:
      class-name: Adam
#      args:


autoencoder:
  latent-dim: 5
  # weight for Kullback-Leibler divergence in loss function
  kl-weight: 0.5
  epochs: 100
  batch-size: 2048

data:
  data-set: mit-bih
  location: /home/robin/Documents/lbnl/crd/RealDatasets/ANNOTATIONS/
  train-sets: [ 803 ]
  # define groups of ctu sets for testing. The model will be tested on all of these groups
  test-groups:
  #    train: [ 803, 806 ]
#    805: [ 805 ]
#    806: [ 806 ]
#    820: [ 820 ]

preprocessing:
  # small, medium, large (see preprocessing.py)
  # list of noise, noise-replace, reverse, reverse-replace
  time-steps: 75
  augmentation: [ reverse ]

downstream:
  #  tasks: [ best-fit-pdf]
  tasks: [ kde ]

logging:
  log-location: ./runs/mit-bih/803
  #copies the preprocessed data to the run dir (the same data as the cached one)
  copy-data: false
  use-wandb: true


  wandb:
    project: ctu-13-augment-bih-803
    entity: lbl-crd
